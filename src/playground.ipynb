{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import tiktoken\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from src.utils.vector_store_manager import VectorStoreManager\n",
    "from src.utils.configuration import LoaderConfiguration\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "config = LoaderConfiguration().from_runnable_config(\n",
    "    RunnableConfig(configurable={\"index_name\": \"au-blog-rag-fine-tuned\"})\n",
    ")\n",
    "document_processor = VectorStoreManager(index_name=\"au-blog-rag-fine-tuned\", configuration=config)\n",
    "\n",
    "def count_tokens(text, model=\"gpt-4o-mini\"):\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    t = encoding.encode(text)\n",
    "    return len(t)\n",
    "\n",
    "docs = document_processor.get_all_documents()\n",
    "print(f\"Unique URLS: {len(set([doc['metadata']['source'] for doc in docs]))}\")\n",
    "\n",
    "lengths = [len(doc['content']) for doc in docs]\n",
    "tokens = [count_tokens(doc['content']) for doc in docs]\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "pd.Series(lengths).hist(bins=20, alpha=0.7, color='blue', edgecolor='black', ax=axes[0])\n",
    "axes[0].set_title('Document Lengths')\n",
    "axes[0].set_xlabel('Length (characters)')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "pd.Series(tokens).hist(bins=20, alpha=0.7, color='green', edgecolor='black', ax=axes[1])\n",
    "axes[1].set_title('Document Tokens')\n",
    "axes[1].set_xlabel('Tokens')\n",
    "axes[1].set_ylabel('Count')\n",
    "\n",
    "\n",
    "print(f\"Total documents: {len(lengths)}\\n\")\n",
    "\n",
    "print(f\"Total length: {sum(lengths)}\")\n",
    "print(f\"Average length: {sum(lengths)/len(lengths)}\")\n",
    "print(f\"Max length: {max(lengths)}\\n\")\n",
    "\n",
    "print(f\"Total tokens: {sum(tokens)}\")\n",
    "print(f\"Average tokens: {sum(tokens)/len(tokens)}\")\n",
    "print(f\"Max tokens: {max(tokens)}\")"
   ],
   "id": "ec5abc9fb7639cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T19:57:15.165351Z",
     "start_time": "2025-02-07T19:57:08.799400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"wylupek/au-blog-rag-embedder\")\n",
    "print(model.get_sentence_embedding_dimension())\n",
    "\n",
    "sentences = [\n",
    "    \"Explain the importance of having a \\\"Portfolio\\\" section on a website. How can showcasing past work benefit a business or individual?\",\n",
    "    \"### Sitemap\\n\\n- Home\\n- About us\\n- How we work\\n- Services\\n- Portfolio\\n- Blog\\n- Career\",\n",
    "    \"Business keeps asking questions about what has been done or what is delivered to our clients.\\n\\nWhat you can do:\",\n",
    "    \"Appunite always pushes boundaries and is very creative in ensuring that there is knowledge shared amongst the workspace and to our external stakeholders. This extends itself to overcoming the problem of articles, which are a longer form of writing, that they can be time consuming. There has recently been the addition of the TIL section on our website and is thanks to the initiative of a few Appuniter who said they would like to make something like this happen. They took on the task and are now live on our site:  This is a valuable add to companies where peoples main focus is not writing and is somewhere else, in this case Software development. It allows for shortened pieces which are compacted with knowledge and what one learns is shared regularly.\\n\\n### Akai\\n\\nAs Appunite believes that the future is in the hands and minds of the youth, what better way to take advantage of this and benefit from a fruitful collaboration.\"\n",
    "]\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities.shape)"
   ],
   "id": "6fa2dc24382ffe71",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filipkozlowski/Documents/github/au-blog-rag/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n",
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
